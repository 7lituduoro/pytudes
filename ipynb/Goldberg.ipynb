{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Unreasonable Effectiveness of Character-level Language Models\n",
    "## (and why RNNs are still cool)\n",
    "\n",
    "## By [Yoav Goldberg](http://www.cs.biu.ac.il/~yogo) (2015)\n",
    "#### with minor changes for Python 3 by Peter Norvig (2022)\n",
    "\n",
    "<hr>\n",
    "\n",
    "RNNs, LSTMs and Deep Learning are all the rage, and a recent [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy is doing a great job explaining what these models are and how to train them.\n",
    "It also provides some very impressive results of what they are capable of.  This is a great post, and if you are interested in natural language, machine learning or neural networks you should definitely read it. \n",
    "\n",
    "Go read it now, then come back here. \n",
    "\n",
    "You're back? good. Impressive stuff, huh? How could the network learn to immitate the input like that?\n",
    "Indeed. I was quite impressed as well.\n",
    "\n",
    "However, it feels to me that most readers of the post are impressed by the wrong reasons.\n",
    "This is because they are not familiar with **unsmoothed maximum-liklihood character level language models** and their unreasonable effectiveness at generating rather convincing natural language outputs.\n",
    "\n",
    "In what follows I will briefly describe these character-level maximum-likelihood langauge models, which are much less magical than RNNs and LSTMs, and show that they too can produce a rather convincing Shakespearean prose. I will also show about 30 lines of python code that take care of both training the model and generating the output. Compared to this baseline, the RNNs may seem somehwat less impressive. So why was I impressed? I will explain this too, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Maximum Likelihood Character Level Language Model \n",
    "\n",
    "The name is quite long, but the idea is very simple.  We want a model whose job is to guess the next character based on the previous *n* letters. For example, having seen `ello`, the next characer is likely to be either a commma or space (if we assume is is the end of the word \"hello\"), or the letter `w` if we believe we are in the middle of the word \"mellow\". Humans are quite good at this, but of course seeing a larger history makes things easier (if we were to see 5 letters instead of 4, the choice between space and `w` would have been much easier).\n",
    "\n",
    "We will call *n*, the number of letters we need to guess based on, the _order_ of the language model.\n",
    "\n",
    "RNNs and LSTMs can potentially learn infinite-order language model (they guess the next character based on a \"state\" which supposedly encode all the previous history). We here will restrict ourselves to a fixed-order language model.\n",
    "\n",
    "So, we are seeing *n* letters, and need to guess the *n+1*th one. We are also given a large-ish amount of text (say, all of Shakespear works) that we can use. How would we go about solving this task?\n",
    "\n",
    "Mathematiacally, we would like to learn a function *P(c* | *h)*. Here, *c* is a character, *h* is a *n*-letters history, and *P(c* | *h)* stands for how likely is it to see *c* after we've seen *h*.\n",
    "\n",
    "Perhaps the simplest approach would be to just count and divide (a.k.a **maximum likelihood estimates**). We will count the number of times each letter *c* appeared after *h*, and divide by the total numbers of letters appearing after *h*. The **unsmoothed** part means that if we did not see a given letter following *h*, we will just give it a probability of zero.\n",
    "\n",
    "And that's all there is to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Here is the code for training the model. `fname` is a file to read the characters from. `order` is the history size to consult. Note that we pad the data with `order` leading characters so that we also learn how to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "LM = Dict[str, Counter] # Language Model: lm['Firs'] = [('t', 1.0)]\n",
    "\n",
    "def train_char_lm(fname, order=4) -> LM:\n",
    "    \"\"\"Train an `order`-gram character-level language model on all the text in `fname`.\"\"\"\n",
    "    lm = defaultdict(Counter)\n",
    "    data = (PAD * order) + open(fname).read()\n",
    "    for i in range(len(data) - order):\n",
    "        history, char = data[i:i+order], data[i+order]\n",
    "        lm[history][char]+=1\n",
    "    return {history: normalize(counter) for history, counter in lm.items()}\n",
    "\n",
    "def normalize(counter) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Return (key, val) pairs, normalized so values sum to 1.0, largest first.\"\"\"\n",
    "    total = float(sum(counter.values()))\n",
    "    return [(k, v / total) for k, v in counter.most_common()]\n",
    "\n",
    "PAD = '`' # Character to pad the beginning of a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it on Andrej's Shakespeare text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  167204  832301 4573338 shakespeare_input.txt\n"
     ]
    }
   ],
   "source": [
    "! [ -f shakespeare_input.txt ] || curl -O https://norvig.com/ngrams/shakespeare_input.txt\n",
    "! wc shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now let's do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w', 0.817717206132879),\n",
       " ('r', 0.059625212947189095),\n",
       " ('u', 0.03747870528109029),\n",
       " (',', 0.027257240204429302),\n",
       " (\"'\", 0.017035775127768313),\n",
       " (' ', 0.013628620102214651),\n",
       " ('.', 0.0068143100511073255),\n",
       " ('?', 0.0068143100511073255),\n",
       " ('!', 0.0068143100511073255),\n",
       " (':', 0.005110732538330494),\n",
       " ('n', 0.0017035775127768314)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['ello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 1.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['Firs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 0.16292134831460675),\n",
       " ('L', 0.10674157303370786),\n",
       " ('C', 0.09550561797752809),\n",
       " ('G', 0.0898876404494382),\n",
       " ('M', 0.0593900481540931),\n",
       " ('t', 0.05377207062600321),\n",
       " ('W', 0.033707865168539325),\n",
       " ('s', 0.03290529695024077),\n",
       " ('o', 0.030497592295345103),\n",
       " ('b', 0.024879614767255216),\n",
       " ('w', 0.024077046548956663),\n",
       " ('a', 0.02247191011235955),\n",
       " ('m', 0.02247191011235955),\n",
       " ('n', 0.020064205457463884),\n",
       " ('h', 0.019261637239165328),\n",
       " ('O', 0.018459069020866775),\n",
       " ('i', 0.016853932584269662),\n",
       " ('d', 0.015248796147672551),\n",
       " ('P', 0.014446227929373997),\n",
       " ('c', 0.012841091492776886),\n",
       " ('F', 0.012038523274478331),\n",
       " ('f', 0.011235955056179775),\n",
       " ('g', 0.011235955056179775),\n",
       " ('l', 0.01043338683788122),\n",
       " ('I', 0.009630818619582664),\n",
       " ('B', 0.009630818619582664),\n",
       " ('p', 0.00882825040128411),\n",
       " ('K', 0.008025682182985553),\n",
       " ('r', 0.0072231139646869984),\n",
       " ('A', 0.0056179775280898875),\n",
       " ('H', 0.0040128410914927765),\n",
       " ('k', 0.0040128410914927765),\n",
       " ('e', 0.0032102728731942215),\n",
       " ('T', 0.0032102728731942215),\n",
       " ('D', 0.0032102728731942215),\n",
       " ('y', 0.002407704654895666),\n",
       " ('v', 0.002407704654895666),\n",
       " ('u', 0.0016051364365971107),\n",
       " ('q', 0.0016051364365971107),\n",
       " ('E', 0.0016051364365971107),\n",
       " ('R', 0.0008025682182985554),\n",
       " ('N', 0.0008025682182985554),\n",
       " (\"'\", 0.0008025682182985554)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['rst ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `\"ello\"` is followed by either space, punctuation or `w` (or `r`, `u`, `n`), `\"Firs\"` is pretty much deterministic, and the word following `\"rst \"` can start with pretty much every letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating from the model\n",
    "\n",
    "Generating is also very simple. To generate a letter, we will take the history, look at the last *order* characters, and then sample a random letter based on the corresponding distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_letter(lm, history, order) -> str:\n",
    "    \"\"\"Given the history of characters, sample a random character from the `lm`.\"\"\"\n",
    "    history = history[-order:]\n",
    "    dist = lm[history]\n",
    "    p = random.random()\n",
    "    for c,v in dist:\n",
    "        p = p - v\n",
    "        if p <= 0: return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a passage of *k* characters, we just seed it with the initial history and run letter generation in a loop, updating the history at each turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm, order, nletters=1000) -> str:\n",
    "    \"\"\"Sample a random `nletters`-long passage from `lm`.\"\"\"\n",
    "    history = PAD * order\n",
    "    out = []\n",
    "    for i in range(nletters):\n",
    "        c = generate_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        out.append(c)\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Shakespeare from different order models\n",
    "\n",
    "Let's try to generate text based on different language-model orders. Let's start with something silly:\n",
    "\n",
    "## order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fir ithe threwd\n",
      "BENVOLAFF:\n",
      "DO:\n",
      "A must art\n",
      "As doe\n",
      "she of traest ing; he bere is amnine will man a prand if not shaves, and did, wasky hiscit. I.\n",
      "\n",
      "GLOSE:\n",
      "Wituouly.\n",
      "\n",
      "QUEEDGAR:\n",
      "Muster ence his loneve day\n",
      "whathy, wing unwake give ther\n",
      "you muck,\n",
      "Wit:\n",
      "Thatichme,\n",
      "Thim?\n",
      "\n",
      "Diereply\n",
      "res Caes mus thereat's\n",
      "Witse in hen,\n",
      "NO Somen; tim but you devinvinvy, yount will yould\n",
      "fath\n",
      "whave do merill'd, a mad. I cucid lems; levesord, vaught; pringer iftern and wome AESSIDEMO:\n",
      "Is in a grant und re\n",
      "MARD I knoth theady tor Bir, them; halle of is nothe Niceron rest wit's prawar inceds knoter noblet feir hemas clen.\n",
      "\n",
      "Yeare for facread; and give hemplaut not amn\n",
      "And,\n",
      "The such deacquic\n",
      "at th a lings of thou gonchater.\n",
      "\n",
      "MOGELIA:\n",
      "Wer extraideadviusbaince,\n",
      "MALIETRAY:\n",
      "And by wee: ang is peadar de;\n",
      "Yornall th mord! gues Neithere.\n",
      "\n",
      "KINE:\n",
      "The food.\n",
      "\n",
      "KINGH Enot\n",
      "Hublood\n",
      "I ke hou not shonou dress-dard;\n",
      "HUS:\n",
      "SULIFF:\n",
      "Hece my is frainis;\n",
      "Fords.\n",
      "\n",
      "PISTRUCE:\n",
      "Yous Duke livencioulls my lon hem nes whe ne.\n",
      "\n",
      "Clonsievery crese goor she\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=2)\n",
    "print(generate_text(lm, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order 4 \n",
    "\n",
    "Order 2 was not so great... but what if we increase the order to 4?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First man to\n",
      "not--Charlot's grounds? I have when I shall heavy is alone:\n",
      "Thou do your Almight at hundered at hence.\n",
      "\n",
      "HELENA:\n",
      "No was it ranklins in powere in you. The shall this park-contract and left up that come;\n",
      "Still, my lips,\n",
      "Nor to life, or with all bear dires her worm you it?\n",
      "\n",
      "BENEDICK:\n",
      "Neanmoins! any me this enemy?\n",
      "\n",
      "ROSALIND:\n",
      "I thing that we devise a mannerly into chides.\n",
      "\n",
      "MELUN:\n",
      "Fie, capitol; but he not as banish of thout-vied and more; I will tell the we may oppress then an of the general please when the moreoversal tell commander'd men who lie by this pair life.\n",
      "\n",
      "QUEEN GERTRUDE:\n",
      "And laughter wife. Come to go\n",
      "who is a dog in your for the courers. Who's she might!\n",
      "Black of place music love anger; I have thou shalt hour.\n",
      "\n",
      "CLEONTES:\n",
      "Paris brotherwhelm'd vanish a sister.\n",
      "\n",
      "KING HENRY:\n",
      "Thou known, that, in that hear,\n",
      "That dowry state.\n",
      "\n",
      "VENTINE:\n",
      "Of this fix'd woman and better?\n",
      "\n",
      "First of this bird, profess togethere a few subject!\n",
      "Who comes Brutus, audacious simpless the desper one be\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## order 7\n",
    "\n",
    "Order 4 is already quite reasonable, and reads like English. Just 4 letters history! What if we increase it to 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Clown:\n",
      "\n",
      "HAMLET:\n",
      "Sir, my lord and so\n",
      "rushling, I say.\n",
      "\n",
      "First Commoners grace, the moon: but the window, bids you, for I stay there was as much, would I were about with some help.\n",
      "\n",
      "CARDINAL WOLSEY:\n",
      "You should shed forced me.\n",
      "\n",
      "KENT:\n",
      "Royally!\n",
      "Where the love of such dulcet,\n",
      "His wife's firm to be a villains' throats too dear a letter.\n",
      "\n",
      "Second Gentleman:\n",
      "Their weapons.\n",
      "\n",
      "ALONSO:\n",
      "Irreparable is the next day's deed: now thou sweatest! comes here.\n",
      "\n",
      "ADRIANA:\n",
      "God bless he purpose of yourself this world.\n",
      "\n",
      "ANTONIO:\n",
      "And so art thou injurer of my soldiers?\n",
      "Though my child, let us to exclaim of every thing, which is in practise,\n",
      "Is all too strict account\n",
      "Of all these instructs you; for you.\n",
      "\n",
      "MENENIUS:\n",
      "Nay: in that our death eaten in this youthful deeds\n",
      "Do breed a kind of death\n",
      "is too long.\n",
      "\n",
      "GONZALO:\n",
      "Heaven for friend, which within fourteen,' an hour my though you were bed-time?\n",
      "Warwick and you my staff of France that night:\n",
      "I stay the time of no mercy.\n",
      "\n",
      "EARL OF DOUGLAS:\n",
      "There is Lord Scales\n",
      "Unto t\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=7)\n",
    "print(generate_text(lm, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about order 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Nay, you must\n",
      "Forget that by hanging of the maids a-row and bound them.\n",
      "\n",
      "ADRIANA:\n",
      "To fetch my poor distressed lord, even such delightful pleasing to a man. O, be some of them have scope to beat,\n",
      "Since foes have scope;\n",
      "Do what you heard not?\n",
      "\n",
      "Gentlewoman?\n",
      "What is't but to breathe in fruitful meal would set down--\n",
      "As best thou diest!\n",
      "\n",
      "SOMERSET:\n",
      "Here in the tender honour of his merit.\n",
      "\n",
      "CORIOLANUS:\n",
      "Not of a woman; if you bear a many superfluity. See, our best leisure, I would\n",
      "repent out the rivet: and at her late beloved,\n",
      "And the moon\n",
      "may shine in pearl and gold,\n",
      "To wait upon your epileptic visage!\n",
      "Smile you my speech. If that thy question,\n",
      "But that you know\n",
      "The worst of all,\n",
      "How we may praise the power of Englishmen unto these, and with bold spirit instructions yet commence\n",
      "Rough deeds of malice;\n",
      "You have heard\n",
      "The fundamental reasons of your law;\n",
      "Therefore be suspicious\n",
      "I more inclined to blood,\n",
      "You, brother Jaques he keeps at school, and\n",
      "report speaks loud; and I say besi\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=10)\n",
    "print(generate_text(lm, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This works pretty well\n",
    "\n",
    "With an order of 4, we already get quite reasonable results. Increasing the order to 7 (about a word and a half of history) or 10 (about two short words of history) already gets us quite passable Shakepearan text. I'd say it is on par with the examples in Andrej's post. And how simple and un-mystical the model is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So why am I impressed with the RNNs after all?\n",
    "\n",
    "Generating English a character at a time -- not so impressive in my view. The RNN needs to learn the previous *n* letters, for a rather small *n*, and that's it. \n",
    "\n",
    "However, Karpathy's C++ code generation example is very impressive. Why? because of the context awareness. Note that in all of Karpathy's posted examples, the code is well indented, the braces and brackets are correctly nested, and even the comments start and end correctly. This is not something that can be achieved by simply looking at the previous *n* characters. \n",
    "\n",
    "If Karpathy's examples are not cherry-picked, and the output is generally that nice, then the LSTM did learn something not trivial at all.\n",
    "\n",
    "# Linux Kernel C++ Code\n",
    "\n",
    "Just for the fun of it, let's see what our simple language model does with the Linux-kernel code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  241465  759639 6206997 linux_input.txt\n"
     ]
    }
   ],
   "source": [
    "! [ -f linux_input.txt ] || curl -O https://norvig.com/ngrams/linux_input.txt\n",
    "! wc linux_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/signal.c\n",
      " *\n",
      " *  Copyright 2005, Red Hat, Inc., Ingo Molnar <mingo@redhat.com>\n",
      " *\n",
      " *  Group scheduling (such as\n",
      " *\tprintk(). Otherwise length is in len field, then array[0] and array[1] has the dual advantage that\n",
      "\t * cgroup_task_get(p);\n",
      "\n",
      "\tif (quota < min_cfs_quota_us < 0)\n",
      "\t\t\tsig->group_exit_task(struct task_struct *tsk, int group_balance_cpu(sg) == cpu)\n",
      "\t\ttick_do_update_jiffies64(now);\n",
      "\t}\n",
      "}\n",
      "\n",
      "#ifdef CONFIG_RCU_BOOST */\n",
      "\n",
      "\t\t/*\n",
      "\t\t * We must manually\n",
      " *\tfree IRQs allocated image pages, but is unlikely.\n",
      "\t * The load balanced, sd->sbf_pushed,\n",
      "\t\t\t     TAINT_WARN, NULL);\n",
      "\tcd.wrap_kt = ns_to_ktime(wrap);\n",
      "\n",
      "\trd = cd.read_data {\n",
      "\tint\t\t\t\tcpu;\n",
      "\tatomic_set(&mm->mm_count);\n",
      "\t\t\tmdelay(1);\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tmutex_lock(&ftrace_lock);\n",
      "\tret = 0;\n",
      "\t}\n",
      "\n",
      "\tfor_each_buffer_cpu(buffer, cpu);\n",
      "\t\tif (retval)\n",
      "\t\tkfree(uprobe);\n",
      "\t\tkfree(ops);\n",
      "\t}\n",
      "\n",
      "\treturn ret;\n",
      "}\n",
      "\n",
      "struct cfs_rq *cfs_rq = &rq->cfs;\n",
      "\tstruct rcu_head rcu;\n",
      "\tstruct sigqueue structure. */\n",
      "\tunsigned long val, void *v)\n",
      "{\n",
      "\tstruct module *mod, char *buf)\n",
      "{\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=10)\n",
    "print(generate_text(lm, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/seccomp.c\n",
      " *\n",
      " * Copyright (C) 2012 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>\n",
      " *\n",
      " */\n",
      "#include <linux/uaccess.h>\n",
      "#include <linux/hardirq.h>\n",
      "#include <linux/async.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/list.h>\n",
      "#include <linux/syscalls.h>\n",
      "#include <linux/cgroup.h>\n",
      "#include <linux/kernel_stat.h>\n",
      "#include <linux/ctype.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/types.h>\n",
      "#include <linux/kallsyms.h>\n",
      "\n",
      "#include \"internals.h\"\n",
      "\n",
      "/*\n",
      " * lockdep_lock: protects the local module list.\n",
      " */\n",
      "static LIST_HEAD(pmus);\n",
      "static DEFINE_RAW_SPINLOCK(clockevents_lock);\n",
      "/* Protection for unbind operations */\n",
      "static void zap_class(struct lockdep_map *lock,\n",
      "\t\t\t   unsigned long long) region->start_pfn << PAGE_SHIFT;\n",
      "}\n",
      "\n",
      "#define DEFINE_FETCH_memory(type)\t\t\t\t\t\\\n",
      "static int filter_opstack_empty(ps))\n",
      "\t\treturn OP_NONE;\n",
      "\n",
      "\topstack_op = list_first_entry(tasks, struct task_struct *tsk, unsigned int type;\n",
      "\tunsigned int i, j, n_pages;\n",
      "\n",
      "\t*size = PAGE_ALIGN(*size);\n",
      "\tn_pages = *size >>\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=15)\n",
    "print(generate_text(lm, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/msi.c\n",
      " *\n",
      " * Copyright (C) 1999-2004 Silicon Graphics, Inc.  All Rights Reserved.\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful,\n",
      " *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU General Public License\n",
      " * as published by the Free Software Foundation.\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful,\n",
      " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU General Public License\n",
      " * along with this program; if not, write to the Free Software\n",
      " * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307  USA\n",
      " *\n",
      " * Written by Rickard E. (Rik) Faith <faith@redhat.com>\n",
      " *\n",
      " * Goals: 1) Integrate fully with Security Modules.\n",
      " *\t  2) Minimal run-time overhead:\n",
      " *\t     a) Minimal when syscall auditing is disabled (audit_enable=0).\n",
      " *\t     b) Small when s\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=20)\n",
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/msi.c\n",
      " *\n",
      " * Copyright (C) 2008 Ingo Molnar <mingo@redhat.com>\n",
      " *\n",
      " * Originally ported from the -rt patch by:\n",
      " *   Copyright (C) 2007 Red Hat, Inc., Peter Zijlstra <pzijlstr@redhat.com>\n",
      " *\n",
      " */\n",
      "#include <linux/bpf.h>\n",
      "#include <linux/mm.h>\n",
      "#include <linux/init.h>\n",
      "#include <linux/sched.h>\n",
      "#include <linux/syscalls.h> here,\n",
      "    but tell gcc to not warn with -Wmissing-prototypes  */\n",
      "asmlinkage long sys_ni_syscall(void)\n",
      "{\n",
      "\treturn -ENOSYS;\n",
      "}\n",
      "\n",
      "int proc_doulongvec_ms_jiffies_minmax, 09/08/99, Carlos H. Bauer.\n",
      " * Added proc_doulongvec_minmax(void *data, struct pt_regs *regs)\n",
      "{\n",
      "\tstruct kretprobe_instance *ri,\n",
      "\t\t    struct pt_regs *regs, u64 mask)\n",
      "{\n",
      "\tint bit;\n",
      "\n",
      "\tfor_each_set_bit(bit, (const unsigned long shortdelay_us = 10;\n",
      "\tconst unsigned long *ipb = b;\n",
      "\n",
      "\tif (*ipa > *ipb)\n",
      "\t\treturn 1;\n",
      "\tif (*ipa < *ipb)\n",
      "\t\treturn -1;\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int trace_search_list(struct list_head *head)\n",
      "{\n",
      "\tstruct perf_event *leader)\n",
      "{\n",
      "\tstruct perf_cgroup *cgrp;\n",
      "\tstruct cgroup_root *root = cgroup_root\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/spurious.c\n",
      " *\n",
      " * Copyright (C) 1998-2005 Pavel Machek <pavel@ucw.cz>\n",
      " * Copyright (C) 2000-2001 VERITAS Software Corporation.\n",
      " * Copyright (C) 2008 Thomas Gleixner <tglx@linutronix.de>\n",
      " *  Copyright (C) 2006 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.\n",
      " *\n",
      " * This file contains functions which manage clocksource drivers to be unregistered\n",
      " *\n",
      " *\tUnregisters a previously registered entries. */\n",
      "\twhile ((info = gcov_info_next(info))) {\n",
      "\t\tgcov_event(GCOV_ADD, info);\n",
      "\t\tcond_resched();\n",
      "\t\tdst += n;\n",
      "\t\tusrc += n;\n",
      "\t\tlen -= n;\n",
      "\t} while (len);\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "/* Sets info->hdr and info->len. */\n",
      "static int copy_module_from_user(umod, len, &info);\n",
      "\tif (err)\n",
      "\t\treturn err;\n",
      "\n",
      "\treturn load_module(&info, uargs, 0);\n",
      "}\n",
      "\n",
      "SYSCALL_DEFINE1(getsid, pid_t, pid)\n",
      "{\n",
      "\tstruct task_struct *p,\n",
      "\t       struct cpumask *later_mask);\n",
      "void cpudl_set(struct cpudl *cp, int idx)\n",
      "{\n",
      "\tint l, r, largest;\n",
      "\n",
      "\t/* adapted from lib/prio_heap.c */\n",
      "\twhile(1) {\n",
      "\t\tl = left_child(idx);\n",
      "\t\tr = right_child(idx);\n",
      "\t\tlargest = idx;\n",
      "\n",
      "\t\tif ((l < cp->size) && dl_time_before(cp->elements[parent(old_idx)].dl,\n",
      "\t\t\t\tcp->elements[old_idx].cpu = new_cpu;\n",
      "\t\tcp->size--;\n",
      "\t\tcp->elements[new_cpu].idx = old_idx;\n",
      "\t\tcp->elements[cpu].idx = IDX_INVALID;\n",
      "\t\twhile (old_idx > 0 && dl_time_before(cp->elements[parent(idx)].dl,\n",
      "\t\t\t\t\tcp->elements[idx].dl)) {\n",
      "\t\t\tcpudl_exchange(cp, idx, parent(idx));\n",
      "\t\t\tidx = parent(idx);\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "\n",
      "static struct dentry *rcudir;\n",
      "\n",
      "static int __init coredump_filter_setup);\n",
      "\n",
      "#include <linux/irq.h>\n",
      "#include <linux/syscalls.h>\n",
      "#include <linux/stop_machine.h>\n",
      "#include <linux/errno.h>\n",
      "#include <linux/export.h>\n",
      "#include <linux/fs_struct.h>\n",
      "\n",
      "static struct kmem_cache *user_ns_cachep __read_mostly;\n",
      "static atomic_t nr_comm_events __read_mostly;\n",
      "\n",
      "static DEFINE_PER_CPU(struct hrtimer_cpu_base *cpu_base = base->cpu_base;\n",
      "\tenum hrtimer_restart __hrtimer_tasklet_trampoline(struct hrtimer *timer)\n",
      "{\n",
      "\tdebug_hrtimer_activate(struct hrtimer *timer)\n",
      "{\n",
      "\tstruct k_itimer *tmr;\n",
      "\n",
      "\twhile (!list_empty(&queue->list)) {\n",
      "\t\tq = list_entry(queue->next, struct sched_rt_entity *rt_se)\n",
      "{\n",
      "\tstruct sched_rt_entity *next = NULL;\n",
      "\tstruct list_head tmp_list;\n",
      "\tstruct uprobe_consumer *uc)\n",
      "{\n",
      "\tconsumer_add(uprobe, uc);\n",
      "\treturn register_tracer(&mmio_tracer);\n",
      "}\n",
      "device_initcall(clockevents_init_sysfs(void)\n",
      "{\n",
      "\tint err = subsys_system_register(&clocksource_jiffies);\n",
      "}\n",
      "\n",
      "core_initcall(perf_workqueue_init);\n",
      "\n",
      "static inline int perf_fget_light(int fd, struct fd *p)\n",
      "{\n",
      "\tstruct fd f = fdget(ufd);\n",
      "\tstruct bpf_map *map_ptr;\n",
      "\t};\n",
      "};\n",
      "\n",
      "enum bpf_stack_slot_type {\n",
      "\tSTACK_INVALID,    /* nothing was stored in this stack slot */\n",
      "\tSTACK_SPILL,      /* register spilled into stack */\n",
      "\tSTACK_MISC\t  /* BPF program wrote some data into this slot */\n",
      "};\n",
      "\n",
      "#define BPF_REG_SIZE 8\t/* size of eBPF register in bytes */\n",
      "\n",
      "/* state of the program:\n",
      " * type of all registers and stack info\n",
      " */\n",
      "struct verifier_stack_elem *head; /* stack of verifier states used to prune search */\n",
      "struct verifier_env *env, u32 regno,\n",
      "\t\t\t  enum bpf_arg_type arg_type, struct bpf_map **mapp)\n",
      "{\n",
      "\tstruct reg_state regs[MAX_BPF_REG];\n",
      "\tu8 stack_slot_type[MAX_BPF_STACK + off + i] != STACK_MISC) {\n",
      "\t\t\tverbose(\"invalid indirect read from stack off %d+%d size %d\\n\",\n",
      "\t\t\t\t\toff, i, size);\n",
      "\t\t\t\treturn -EACCES;\n",
      "\t\t}\n",
      "\t\terr = check_pred_tree(filter, root);\n",
      "\t\tif (err)\n",
      "\t\t\tgoto out;\n",
      "\n",
      "\t\t/* Prepare optimized instructions and optimized_kprobe */\n",
      "static void freezer_fork(struct task_struct *task)\n",
      "{\n",
      "\tstruct freezer *freezer)\n",
      "{\n",
      "\treturn css_freezer(freezer->css.parent);\n",
      "}\n",
      "\n",
      "bool cgroup_freezing(struct task_struct *p)\n",
      "{\n",
      "\treturn dl_policy(p->policy);\n",
      "}\n",
      "\n",
      "static inline void update_load_sub(struct load_weight *lw)\n",
      "{\n",
      "\tu64 fact = scale_load_down(weight);\n",
      "\tint shift = WMULT_SHIFT;\n",
      "\n",
      "\t__update_inv_weight(lw);\n",
      "\n",
      "\tif (unlikely(fact >> 32)) {\n",
      "\t\twhile (fact >> 32) {\n",
      "\t\t\tfact >>= 1;\n",
      "\t\t\tshift--;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\t/* hint to use a 32x32->64 mul */\n",
      "\tfact = (u64)(u32)fact * lw->inv_weight;\n",
      "\n",
      "\twhile (fact >> 32) {\n",
      "\t\t\tfact >>= 1;\n",
      "\t\t\tshift--;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\t/* hint to use a 32x32->64 mul */\n",
      "\tfact = (u64)(u32)fact * lw->inv_weight;\n",
      "\n",
      "\twhile (fact >> 32) {\n",
      "\t\tfact >>= 1;\n",
      "\t\tshift--;\n",
      "\t}\n",
      "\n",
      "\treturn mul_u64_u32_shr(delta_exec, fact, shift);\n",
      "}\n",
      "\n",
      "\n",
      "const struct sched_class idle_sched_class;\n",
      "\n",
      "\n",
      "#ifdef CONFIG_SMP\n",
      "\t\tif (!rq->rd->overload)\n",
      "\t\t\trq->rd->overload = true;\n",
      "#endif\n",
      "\n",
      "#ifdef CONFIG_CPU_IDLE\n",
      "\t/* Must be inspected within a rcu lock section */\n",
      "\tstruct cpuidle_state *idle_state)\n",
      "{\n",
      "\trq->idle_state = idle_state;\n",
      "}\n",
      "\n",
      "static inline int\n",
      "prepare_highmem_image - try to allocate as many highmem pages as there are\n",
      " *\tsaveable highmem pages in the system.  If that fails, we allocate\n",
      " *\tnon-highmem pages for the image.\n",
      " *\tTry to allocate as many highmem pages as\n",
      " *\tthere are highmem image pages (@nr_highmem_p points to the variable\n",
      " *\tcontaining the number of highmem pages in the system.  If that fails, we allocate\n",
      " *\tnon-highmem pages for the copies of the remaining highmem ones.\n",
      " *\n",
      " *\tIn this approach it is likely that the copies of highmem pages will\n",
      " *\talso be located in the high memory, because of the way in which\n",
      " *\tcopy_data_pages() works.\n",
      " */\n",
      "\n",
      "stat\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, 20, nletters=5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Order 10 is pretty much junk. In order 15 things sort-of make sense, but we jump abruptly between the `[sic]`\n",
    "and by order 20 we are doing quite nicely -- but are far from keeping good indentation and brackets. \n",
    "\n",
    "How could we? we do not have the memory, and these things are not modeled at all. While we could quite easily enrich our model to support also keeping track of brackets and indentation (by adding information such as \"have I seen ( but not )\" to the conditioning history), this requires extra work, non-trivial human reasoning, and will make the model significantly more complex. \n",
    "\n",
    "Karpathy's LSTM, on the other hand, seemed to have just learn it on its own. And that's impressive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
